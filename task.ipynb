{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2878b505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pyspark\\sql\\context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.setMaster(\"local\").setAppName(\"flask_app\")\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "from pyspark import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f426a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8ce2190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "engine = create_engine(\n",
    "    \"postgresql+psycopg2://root:root@localhost/test_db?client_encoding=utf8\")\n",
    "pd_actor = pd.read_sql('select * from public.actor', engine)\n",
    "pd_address = pd.read_sql('select * from public.address', engine)\n",
    "pd_category = pd.read_sql('select * from public.category', engine)\n",
    "pd_city = pd.read_sql('select * from public.city', engine)\n",
    "pd_country = pd.read_sql('select * from public.country', engine)\n",
    "pd_custormer = pd.read_sql('select * from public.customer', engine)\n",
    "pd_film = pd.read_sql('select * from public.film', engine)\n",
    "pd_film_actor = pd.read_sql('select * from public.film_actor', engine)\n",
    "pd_film_category = pd.read_sql('select * from public.film_category', engine)\n",
    "pd_invenotory = pd.read_sql('select * from public.inventory', engine)\n",
    "pd_language = pd.read_sql('select * from public.language', engine)\n",
    "pd_payment = pd.read_sql('select * from public.payment', engine)\n",
    "pd_rental = pd.read_sql('select * from public.rental', engine)\n",
    "pd_staff = pd.read_sql('select * from public.staff', engine)\n",
    "pd_store = pd.read_sql('select * from public.store', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b3e75d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>staff_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>address_id</th>\n",
       "      <th>email</th>\n",
       "      <th>store_id</th>\n",
       "      <th>active</th>\n",
       "      <th>username</th>\n",
       "      <th>password</th>\n",
       "      <th>last_update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mike</td>\n",
       "      <td>Hillyer</td>\n",
       "      <td>3</td>\n",
       "      <td>Mike.Hillyer@sakilastaff.com</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>Mike</td>\n",
       "      <td>8cb2237d0679ca88db6464eac60da96345513964</td>\n",
       "      <td>2020-05-16 15:13:11.793280+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jon</td>\n",
       "      <td>Stephens</td>\n",
       "      <td>4</td>\n",
       "      <td>Jon.Stephens@sakilastaff.com</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>Jon</td>\n",
       "      <td>8cb2237d0679ca88db6464eac60da96345513964</td>\n",
       "      <td>2020-05-16 15:13:11.793280+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   staff_id first_name last_name  address_id                         email  \\\n",
       "0         1       Mike   Hillyer           3  Mike.Hillyer@sakilastaff.com   \n",
       "1         2        Jon  Stephens           4  Jon.Stephens@sakilastaff.com   \n",
       "\n",
       "   store_id  active username                                  password  \\\n",
       "0         1    True     Mike  8cb2237d0679ca88db6464eac60da96345513964   \n",
       "1         2    True      Jon  8cb2237d0679ca88db6464eac60da96345513964   \n",
       "\n",
       "                       last_update  \n",
       "0 2020-05-16 15:13:11.793280+00:00  \n",
       "1 2020-05-16 15:13:11.793280+00:00  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_staff.drop(columns=['picture'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "836e39f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "df_actor = spark.createDataFrame(pd_actor)\n",
    "df_address = spark.createDataFrame(pd_address)\n",
    "df_category = spark.createDataFrame(pd_category)\n",
    "df_city = spark.createDataFrame(pd_city)\n",
    "df_country = spark.createDataFrame(pd_country)\n",
    "df_customer = spark.createDataFrame(pd_custormer)\n",
    "\n",
    "film_schemas = StructType([\n",
    "    StructField('film_id', IntegerType(), True),\n",
    "    StructField('title', StringType(), True),\n",
    "    StructField('description', StringType(), True),\n",
    "    StructField('release_year', IntegerType(), True),\n",
    "    StructField('language_id', IntegerType(), True),\n",
    "    StructField('original_language_id', IntegerType(), True),\n",
    "    StructField('rental_duration', IntegerType(), True),\n",
    "    StructField('rental_rate', DoubleType(), True),\n",
    "    StructField('length', IntegerType(), True),\n",
    "    StructField('replacement_cost', DoubleType(), True),\n",
    "    StructField('rating', StringType(), True),\n",
    "    StructField('last_update', TimestampType(), True),\n",
    "    StructField('special_features', StringType(), True),\n",
    "    StructField('fulltext', StringType(), True),\n",
    "])\n",
    "\n",
    "df_film = spark.createDataFrame(pd_film, schema=film_schemas)\n",
    "df_film_actor = spark.createDataFrame(pd_film_actor)\n",
    "df_film_category = spark.createDataFrame(pd_film_category)\n",
    "df_invenotry = spark.createDataFrame(pd_invenotory)\n",
    "df_language = spark.createDataFrame(pd_language)\n",
    "df_payment = spark.createDataFrame(pd_payment)\n",
    "df_rental = spark.createDataFrame(pd_rental)\n",
    "\n",
    "staff_schemas = StructType([\n",
    "    StructField('staff_id', IntegerType(), True),\n",
    "    StructField('first_name', StringType(), True),\n",
    "    StructField('last_name', StringType(), True),\n",
    "    StructField('address_id', IntegerType(), True),\n",
    "    StructField('email', StringType(), True),\n",
    "    StructField('store_id', IntegerType(), True),\n",
    "    StructField('active', IntegerType(), True),\n",
    "    StructField('username', StringType(), True),\n",
    "    StructField('password', StringType(), True),\n",
    "    StructField('last_update', TimestampType(), True),\n",
    "])\n",
    "\n",
    "df_staff = spark.createDataFrame(pd_staff.drop(columns=['picture']))\n",
    "df_store = spark.createDataFrame(pd_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4121b86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+----------+-------------------+\n",
      "|store_id|manager_staff_id|address_id|        last_update|\n",
      "+--------+----------------+----------+-------------------+\n",
      "|       1|               1|         1|2020-02-15 12:57:12|\n",
      "|       2|               2|         2|2020-02-15 12:57:12|\n",
      "+--------+----------------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_store.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5ef3ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
